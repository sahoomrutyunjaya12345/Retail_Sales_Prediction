{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahoomrutyunjaya12345/Retail_Sales_Prediction/blob/main/Mrutyunjaya_Sahoo_Regression_capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **RETAIL SALES PREDICTION**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member-** MRUTYUNJAYA SAHOO\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/sahoomrutyunjaya12345/Retail_Sales_Prediction.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import missingno as msno\n",
        "\n",
        "# Adding this to ignore future warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nNjoGsRjsnbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "rossmann_df = pd.read_csv(\"/content/drive/MyDrive/REGRESSION CAPSTONE PROJECT/Rossmann Stores Data.csv\")\n",
        "store_df = pd.read_csv(\"/content/drive/MyDrive/REGRESSION CAPSTONE PROJECT/store.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look of rossmann_df\n",
        "rossmann_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look of Store_df\n",
        "store_df.head()"
      ],
      "metadata": {
        "id": "IUe1sxC_t5zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rossmann_df.shape, store_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info of rossmann_df\n",
        "rossmann_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info of store_df\n",
        "store_df.info()"
      ],
      "metadata": {
        "id": "ueKtqMZmurRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset duplicate value counts of rossmann_df \n",
        "len(rossmann_df[rossmann_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset duplicate value counts of store_df\n",
        "len(store_df[store_df.duplicated()])"
      ],
      "metadata": {
        "id": "XqcmcC9G04Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count rossmann_df\n",
        "rossmann_df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Missing Values/Null Values Count of store_df\n",
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "g6C2M3VN2ywJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(rossmann_df,figsize=(10,5), color=\"tab:blue\")"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(store_df,figsize=(10,5), color=\"tab:green\")"
      ],
      "metadata": {
        "id": "LSyFVKE0-fz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above operation we understand about these datasets such as\n",
        "\n",
        "1. **rossmann dataset** have **1017209 rows and 9 columns** and it doesn't have any null values.\n",
        "2. **store dataset** have **1115 rows and 10 columns** and **store dataset** have null values in total **six features** viz. CompetitionDistance,CompetitionOpenSinceMonth, CompetitionOpenSinceYear, Promo2SinceWeek,Promo2SinceYear and PromoInterval.\n",
        "3. There are ** no duplicate** values present in both **rossmann and store** datasets. "
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "rossmann_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.columns"
      ],
      "metadata": {
        "id": "SJpIPFcdEi30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "rossmann_df.describe(include=\"all\")"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.describe(include=\"all\")"
      ],
      "metadata": {
        "id": "QhDwCd3NEt6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann Stores Data.csv** - historical data including Sales\n",
        "\n",
        "**Store.csv** - supplemental information about the stores\n",
        "\n",
        "## Data fields:\n",
        "\n",
        "1. Id - an Id that represents a (Store, Date) duple within the test set\n",
        "\n",
        "2. Store - a unique Id for each store\n",
        "\n",
        "3. Sales - the turnover for any given day (this is what you are predicting)\n",
        "\n",
        "4. Customers - the number of customers on a given day\n",
        "\n",
        "5. Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "\n",
        "6. StateHoliday - indicates a state holiday.\n",
        "\n",
        "7. SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "\n",
        "8. StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "\n",
        "9. Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "\n",
        "10. CompetitionDistance - distance in meters to the nearest competitor store\n",
        "\n",
        "11. CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "\n",
        "12. Promo - indicates whether a store is running a promo on that day\n",
        "\n",
        "13. Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "\n",
        "14. Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "\n",
        "15. PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started a new. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in rossmann_df.columns:\n",
        "  print(\"The Unique Values of', i, 'are:\", rossmann_df[i].unique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in store_df.columns:\n",
        "  print(\"The Unique Values of', i, 'are:\", store_df[i].unique())"
      ],
      "metadata": {
        "id": "04ZTun7oFu72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "rossmann_df.isnull().sum(),  rossmann_df.info()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking null values for store dataset\n",
        "store_df.info(),  store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "hORewfrnfnzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling all null values of store dataset with 0\n",
        "\n",
        "store_df.fillna({\"CompetitionDistance\":0},inplace=True)\n",
        "store_df.fillna({\"CompetitionOpenSinceMonth\":0},inplace=True)\n",
        "store_df.fillna({\"CompetitionOpenSinceYear\":0},inplace=True)\n",
        "store_df.fillna({\"Promo2SinceWeek\":0},inplace=True)\n",
        "store_df.fillna({\"Promo2SinceYear\":0},inplace=True)\n",
        "store_df.fillna({\"PromoInterval\":0},inplace=True)"
      ],
      "metadata": {
        "id": "A8Nz4NRYfnfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing duplicate value from both dataset if any\n",
        "rossmann_df.duplicated().sum()\n",
        "rossmann_df.drop_duplicates(inplace=True)\n",
        "\n",
        "store_df.duplicated().sum()\n",
        "store_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "n9KNT4LsfnEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging two dataset using inner join\n",
        "final_dataset=pd.merge(rossmann_df,store_df,on = \"Store\" ,how=\"inner\")\n",
        "final_dataset.head()"
      ],
      "metadata": {
        "id": "FkqkkdKJfmjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing dtype into required format from final the datasets\n",
        "final_dataset[\"Date\"]= pd.to_datetime(final_dataset[\"Date\"],format=\"%Y/%m/%d\")\n",
        "final_dataset[\"CompetitionDistance\"]= final_dataset[\"CompetitionDistance\"].astype(int)\n",
        "final_dataset[\"CompetitionOpenSinceMonth\"]= final_dataset[\"CompetitionOpenSinceMonth\"].astype(int)\n",
        "final_dataset[\"CompetitionOpenSinceYear\"]= final_dataset[\"CompetitionOpenSinceYear\"].astype(int)\n",
        "final_dataset[\"Promo2SinceWeek\"]= final_dataset[\"Promo2SinceWeek\"].astype(int)\n",
        "final_dataset[\"Promo2SinceYear\"]= final_dataset[\"Promo2SinceYear\"].astype(int)"
      ],
      "metadata": {
        "id": "nOE5nlnz2AJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.info(),final_dataset.shape"
      ],
      "metadata": {
        "id": "w7WU9_sVt-_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We Checked the null values in both rossmann_df dataset but there is no null values and store_df dataset has some  columns have null values.So we replaced all null values with 0 and after replacing the null values we merged the two datset and also changed the data type of some columns to as per date time and int, for our better understanding . When we are going to check different featues relation between them and visualize them with some charts it will give us a meaningfull and a clear outlook of it. "
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 1: Sales vs Frequency"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.xlabel(\"Sales\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "sns.kdeplot(final_dataset[\"Sales\"], color=\"Blue\",shade=True)\n",
        "plt.title('Density distribution of Sales',size = 15)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Check the frequency of sales happening over this density distribution graph "
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here from this graph we found average stores are rightly skewed ."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw from this density distribution graph we found that many stores are located in perfectly and also the sales are average, yes to sustain be competitive."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Chart - 2: Customers vs Frequency"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(2,2,3)\n",
        "plt.xlabel(\"Customers\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "sns.kdeplot(final_dataset[\"Customers\"], color=\"green\", shade = True)\n",
        "plt.title('Density distribution of Customers',size = 25)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this density distribution graph based on customer we found how customers are visting to the store."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this customer distribution graph we understand average customers are visting to store is 1000."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw from this frequency distribution graph on customer we found that there is postive response from customer as the data showinng average customers are 1000. so we understand to be more profit we have to take some hard decision to improve our customer."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 3: DayOfWeek vs Sales\n"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(16,8))\n",
        "sns.factorplot(x=\"DayOfWeek\" ,y = \"Sales\" , data=final_dataset, kind=\"point\", aspect=2,size=6)"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this graph we understand Sales of every day in a week"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this plot between Sales and dayofweek,we understand that sales are high on opening days but gradually decreasing and shows that maximum sales is on Monday and sales gradually decreasing to 6th day of week i.e. on saturday and  sales on Sunday is almost near to Zero as on sunday maximum stores are closed."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes from this we can increase our sales on the day where sales are high by taking different competitive methods. "
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 4: Open vs Sales"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "result=final_dataset.groupby(['Open'],as_index=False).agg({'Sales':\"sum\"})\n",
        "print(result)\n",
        "# plot the result\n",
        "sns.barplot(x = 'Open', y = 'Sales',data=result)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the sales when store's are open and closed."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes when stores are closed there is no sales but when store's are open it's high in sales."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from this count plot we finally understand how exactly sales are, so we can improve according to that."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 5: Assortment vs Sales"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Assort_sale=final_dataset.groupby(['StoreType','Assortment'],as_index=False).agg({'Sales':'count'})\n",
        "sns.barplot(x='StoreType',y='Sales',hue='Assortment',data=Assort_sale)"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand what type of assortment is sold in every store."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "from this bar plot we understand:\n",
        "Store type a has a and c type assortment,\n",
        "Store type b has a and b type assortment,\n",
        "Store type c has a and c type assortment,\n",
        "Store type d has a and c type assortment.\n",
        "Assortment type a is sold more which means their demand is high followed by type c,\n",
        "b has the least sales which might mean they are high quality product and also they are available only in store type b."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot givees us  details about which type of assortment is highly sold in which type of store."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 6: Customers vs Sales"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(6,7))\n",
        "sns.scatterplot(final_dataset['Customers'],final_dataset['Sales'])"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose scatter plot because we wanted to plot the relationship between the number of customers visiting the store and the total sales.They are useful for identifying outliers in the data as well."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This scatter plot shows a positive correlation between 'Sales' and 'Customers'. As the number of customers increases, the sales also tend to increase. We understood from the above trend that our data shows in a linearly trend between customers and sales."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers and sales are directly proportional to each other and are highly correlated. It can help businesses to promote their strategies using marketing campaigns, advertisements to attract more customers ultimately increasing up the sales."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart -7: Promo Vs Sales"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.Promo.value_counts().plot.bar()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promo=final_dataset.groupby(['Promo'],as_index=False).agg({'Sales':'mean'})\n",
        "sns.barplot(x=promo.index, y = promo['Sales'])\n",
        "plt.xlabel('Promo')\n"
      ],
      "metadata": {
        "id": "Xt6vOL7DjQrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promo2=final_dataset.groupby(['Promo2'],as_index=False).agg({'Sales':'mean'})\n",
        "sns.barplot(x=promo2.index, y = promo2['Sales'])\n",
        "plt.xlabel('Promo2')"
      ],
      "metadata": {
        "id": "YOrahikyjQWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Understand the promotion of sales"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this barplot between promo vs sales gives us there is promotion occurs for sales to be incresing but in promo2 vs sales there is no promotion occurs."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This detail information will give us the better idea of how much promotion is going on for our sales or how we will do the promotion for our sales"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.columns"
      ],
      "metadata": {
        "id": "wFi9XeKDlU_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 8: CompetitionOpenSinceYear vs Sales"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'CompetitionOpenSinceYear', y= 'Sales', data=final_dataset)\n",
        "plt.title('Plot between Sales and Competition Open Since year')"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the average sales for each year since another competitor opened near the store "
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this point plot we can tell that Sales are high during the year 1900, as there are very few store were operated, so there is less competition and sales are high. But as year passes, number of stores increased that means competition also increased and this leads to decrease in the sales."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since almost every subsequent year reports sudden drop/rise in the sales, owners need to work on their stockings and marketing tactics. The  reason for this change could be explored more deeply and a good decision to be make for the better performance of sales."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 9: SchoolHoliday vs Sales"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plot_SchoolHoliday_sales = sns.barplot(x=\"SchoolHoliday\", y=\"Sales\", data=final_dataset)\n",
        "plt.title('Boxplot For Sales Values')"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the count of how many sales were made at stores on school holiday and on non-school holiday"
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this bar plot we can see there is no diffrece in sales,but sales are more on school holidays . It is possible that school holidays are more likely to be associated with families going on vacation or parents taking time off work to spend with their children, which could lead to increase in consumer spendings."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the graph, it is not making much difference whether there is school holiday or not. Still, businesses can target school holidays and run more promotional offers."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 10: Understanding promoInterval on Stores"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.PromoInterval.value_counts()"
      ],
      "metadata": {
        "id": "aQB5X1nHrqeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "final_dataset.PromoInterval.value_counts().plot.pie(autopct='%1.1f%%', shadow=True)\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the promotion interval i.e. when the store is partcipating or not."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we found from this pie plot there is maximum promotion occurs on jan,apr,jul,oct in this month and there is average 50% stores are not participating for promotion and lowest promotion occurs in mar,jun,sept,dec."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So from this we can understand which month are crucial for promotion and which month are not. So according to that we can make decision for our sales."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 11: CompetitionDistance vs Sales"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.scatterplot(final_dataset['CompetitionDistance'],final_dataset['Sales'])"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand relationship between Cometition distance vs Sales"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above scatter plot we observed that mostly the competitor stores weren't that far from each other and the stores are located near each other saw more sales"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see sales are more for closely located stores and stores can continue providing exciting offers and services to attract customers to compete the market."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 12 : Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr_data = final_dataset.corr()\n",
        "h, ax = plt.subplots(figsize=(20, 12))\n",
        "sns.heatmap(corr_data, vmax=.8, square=True , cmap=\"Greens\",annot=True);"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand relationship between each features."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from this heatmap we can say:\n",
        "\n",
        "*   Store and Sales are almost negligible correlated\n",
        "*   DayofWeek and Sales are negatively(-0.46) correlated\n",
        "*   Customers and Sales are positively (0.89) correlated.\n",
        "*   Promo and Sales are positively (0.45) correlated.\n",
        "*   Open and Sales are positively(0.68) correlated\n",
        "*   All the other features are negligibly correlated with Sales\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart - 13 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(final_dataset)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this pair plot we can understand multiple relationship between diffrent features in a single frame and various insights related to the data can be gained in one single look."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot helped us to visualize the relationship between sales and other variables, such as customers, Promotions, competition, and school holidays Columns."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "final_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have checked the null and duplicate values by isnull(),dupicated() and then replaced the null values of various variables with 0 ."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
        "ax1.hist(final_dataset['Sales'], bins=30)\n",
        "ax2.boxplot(final_dataset['Sales'])"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.distplot(final_dataset['Sales'])"
      ],
      "metadata": {
        "id": "Vk5F6KuqFiE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Outliers Of Sales Column"
      ],
      "metadata": {
        "id": "FZrgfTDuUecW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning continous variable features in new variables so that it makes sense while visulatizing through box plots\n",
        "continous_value_feature= [\"DayOfWeek\", \"Sales\", \"Customers\", \"CompetitionDistance\", \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Promo2SinceWeek\", \"Promo2SinceYear\"]\n",
        "numeric_features= ['Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek','Promo2SinceYear']\n",
        "categorical_features= [\"Date\", \"StoreType\", \"Assortment\", \"PromoInterval\"]"
      ],
      "metadata": {
        "id": "gCpgiJ7OL93g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the function that treats outliers with the IQR technique\n",
        "def treat_outliers_iqr(data):\n",
        "    # Calculate the first and third quartiles\n",
        "    q1, q3 = np.percentile(data, [25, 75])\n",
        "    \n",
        "    # Calculate the interquartile range (IQR)\n",
        "    iqr = q3 - q1\n",
        "    \n",
        "    # Identify the outliers\n",
        "    lower_outlier = q1 - (1.5 * iqr)\n",
        "    upper_outlier = q3 + (1.5 * iqr)\n",
        "    outliers = [x for x in data if x < lower_outlier or x > upper_outlier]\n",
        "    \n",
        "    # Treat the outliers (e.g., replace with the nearest quartile value)\n",
        "    treated_data = [q1 if x < lower_outlier else q3 if x > upper_outlier else x for x in data]\n",
        "    treated_data_int = [int(absolute) for absolute in treated_data]\n",
        "    \n",
        "    return treated_data_int"
      ],
      "metadata": {
        "id": "1xf7Ab4OJgk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Passing all the feature one by one from the list of continous_value_feature in our above defined function for outlier treatment\n",
        "for feature in continous_value_feature:\n",
        "  final_dataset[feature]= treat_outliers_iqr(final_dataset[feature])"
      ],
      "metadata": {
        "id": "EAxmBaclMSgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replotting the box plots and checking outliers still available(if any) in the list of continous_value_feature.\n",
        "plt.figure(figsize=(30,15))\n",
        "for n,column in enumerate(continous_value_feature):\n",
        "  plt.subplot(5, 4, n+1)\n",
        "  sns.boxplot(final_dataset[column])\n",
        "  plt.title(f'{column.title()}',weight='bold')\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "dGFbpgF0MQwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from above Box plot there is no outliers so by using tenchniques like inter quartile range."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "final_dataset.info()"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the variable that contains list of \"object\" dtypes\n",
        "obj= [\"StateHoliday\", \"StoreType\", \"Assortment\", \"PromoInterval\"]\n",
        "\n",
        "\n",
        "# checking the unique counts of object dype column which is essential to determine the type of encoding to use in various column\n",
        "for unique in obj:\n",
        "  print(f\"{unique}: \")\n",
        "  print(f\"The unique values are: {final_dataset[unique].unique()}\")\n",
        "  print(f\"Total number of unique values are: {final_dataset[unique].nunique()}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "1ZXqjVddO83Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing \"0\" to 0 and a,b,c=1 for our simplicity as they resembles that there is holiday\n",
        "final_dataset[\"StateHoliday\"].replace({\"0\":0, \"a\":1, \"b\":1, \"c\":1}, inplace=True)\n",
        "\n",
        "\n",
        "for unique in obj:\n",
        "  print(f\"{unique}: \")\n",
        "  print(f\"The unique values are: {final_dataset[unique].unique()}\")\n",
        "  print(f\"Total number of unique values are: {final_dataset[unique].nunique()}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "-ixa3LoiO8cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our all the categorical columns are nominal in nature(do not have any rank or order) so will use One-Hot Encoding (Type of Nominal encoding) in our senario:"
      ],
      "metadata": {
        "id": "OHKXqKT4QWM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create a copy of dataframe to avoid blunders with our original dataframe\n",
        "final_dataset_1=final_dataset.copy()"
      ],
      "metadata": {
        "id": "dd5rnibWQVDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns by dropping the first category\n",
        "final_dataset_1= pd.get_dummies(final_dataset, dtype=int, drop_first=True)"
      ],
      "metadata": {
        "id": "pnpfPkHUQUtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset_1.info()"
      ],
      "metadata": {
        "id": "jcwG-A_iO8Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used one-hot encoding technique to change our categorical features of object type into int type by creating their dummies so that it becomes compatible to feed it into various ML algorithms in future."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "final_dataset_1.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting date, month and year from Date feature\n",
        "final_dataset_1[\"Day\"]= final_dataset_1[\"Date\"].dt.day\n",
        "final_dataset_1[\"Month\"]= final_dataset_1[\"Date\"].dt.month\n",
        "final_dataset_1[\"Year\"]= final_dataset_1[\"Date\"].dt.year\n",
        "final_dataset_1[\"Week\"]= final_dataset_1[\"Date\"].dt.week"
      ],
      "metadata": {
        "id": "iWx9wLm6SC1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset_1.head()"
      ],
      "metadata": {
        "id": "QUEnXFPgSCdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "plt.figure(figsize=(20,15))\n",
        "sns.heatmap(abs(round(final_dataset_1.corr(),3)), annot=True, cmap=plt.cm.CMRmap)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have plotted the seaborn's scatterplot and seaborn's heatmap to see the relationship of each of the feature with target variable and observed the following correlations:\n",
        " \n",
        "*   Positive Corelation- Customers, Open, Promo, SchoolHoliday, CompetitionOpenSinceYear, Assortment_b, Assortment_c, Month, Year, Week, PromoDuration.\n",
        "\n",
        "*   Negative Corelation- DayOfWeek, StateHoliday, ComptitionDistance, CompetitionOpenSinceMonth, Promo2, Promo2SinceWeek,Promo2SinceYear, 'PromoInterval_Feb,May,Aug,Nov, 'PromoInterval_Jan,Apr,Jul,Oct, PromoInterval_Mar,Jun,Sept,Dec, Day, CompetitionDuration.\n",
        "*   No Corelation- Store, StoreType_c, StoreType_d"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have selected\n",
        " \"DayOfWeek\",\"Customers\",\"Promo\",\"StateHoliday\",\"SchoolHoliday\",\"CompetitionDistance\",\"Promo2\",\"StoreType_b\",\"StoreType_c\",\"StoreType_d\",\"Assortment_c\",\"PromoInterval_Feb,May,Aug,Nov\",\"PromoInterval_Mar,Jun,Sept,Dec\",\"Day\",\"CompetitionDuration\" as our final important features as they are highly correlated with the target variable (Sales)"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3: Feature Engineering"
      ],
      "metadata": {
        "id": "4HdUyUvwiz2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset_1.columns"
      ],
      "metadata": {
        "id": "fNexKnfGjg4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['DayOfWeek', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Promo2SinceWeek', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceYear', 'Promo2SinceWeek']"
      ],
      "metadata": {
        "id": "JQ3XbU0ginCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numeric_features[0:-1]:\n",
        "  fig = plt.figure(figsize=(9,6))\n",
        "  ax = fig.gca()\n",
        "  feature = final_dataset_1[col]\n",
        "  label = final_dataset_1['Sales']\n",
        "  correlation = feature.corr(label)\n",
        "  plt.scatter(x = feature, y=label)\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('Sales')\n",
        "  ax.set_title('Sales vs ' + col + '- correlation: ' + str(correlation))\n",
        "  z = np.polyfit(final_dataset_1[col], final_dataset_1['Sales'], 1)\n",
        "  y_hat = np.poly1d(z)(final_dataset_1[col])\n",
        "\n",
        "  plt.plot(final_dataset_1[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4lPbl1KajBaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 4. Data Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rySt5CI4ETYj"
      },
      "source": [
        "Before scaling our data let's just seperate our \"x\" and \"y\" variables as we do not have to scale our y variable (Target variable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRbjX-I5EqAe"
      },
      "outputs": [],
      "source": [
        "# Separating \"x\" and \"y\" variables\n",
        "x= final_dataset_1[[\"DayOfWeek\", \"Customers\",\"Promo\",\"StateHoliday\",\"SchoolHoliday\",\"CompetitionDistance\",\"Promo2\",\"StoreType_b\",\"StoreType_c\",\"StoreType_d\",\"Assortment_c\",\"PromoInterval_Feb,May,Aug,Nov\",\"PromoInterval_Mar,Jun,Sept,Dec\",\"Day\"]]\n",
        "y= final_dataset_1[['Sales']]\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "# Importing StandardScaler library\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwR6U6a8CtrI"
      },
      "outputs": [],
      "source": [
        "# Creating object\n",
        "std_regressor= StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9moZvVLC26g"
      },
      "outputs": [],
      "source": [
        "# Fit and Transform\n",
        "x= std_regressor.fit_transform(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo23bXec2Brn"
      },
      "source": [
        "We have used StandardScaler of sklearn library to scale our data.  This is important for us, as features on different scales can lead to poor performance or slow convergence. Standardizing the features also makes it easier to compare different features or observe the effect of a feature on the target variable(\"Sales\") by comparing the magnitude of its coefficient. Additionally, we are going to apply linear regression model for which having normally distributed data is the statistical assumption of the model, which standardization can help enforce."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m7brn--dnqdH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 5. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Importing train_test_split from sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjRMKb7RLWuI"
      },
      "outputs": [],
      "source": [
        "# Spliting the dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMo-HZohLnLJ"
      },
      "outputs": [],
      "source": [
        "# Checking the shape after spliting\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "Since our dataset is huge and have nearly 10lakh obsevations. So, We have assigned 80% data into train set and 20% into the test set with random_state=0 so that we do not get different observations in every split."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset_1.shape"
      ],
      "metadata": {
        "id": "3F_YbZVTlyX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing essential libraries to check the accuracy\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "KERVUz2Pl7Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the function that calculated regression metrics\n",
        "def regression_metrics(y_train_actual,y_train_pred,y_test_actual,y_test_pred):\n",
        "  ## mean_absolute_error\n",
        "  MAE_train= mean_absolute_error(y_train,y_train_pred)\n",
        "  print(\"MAE on train is:\" ,MAE_train)\n",
        "  MAE_test= mean_absolute_error(y_test,y_test_pred)\n",
        "  print(\"MAE on test is:\" ,MAE_test)\n",
        "\n",
        "  ## mean_squared_error\n",
        "  MSE_train= mean_squared_error(y_train, y_train_pred)\n",
        "  print(\"MSE on train is:\" ,MSE_train)\n",
        "  MSE_test  = mean_squared_error(y_test, y_test_pred)\n",
        "  print(\"MSE on test is:\" ,MSE_test)\n",
        "\n",
        "  ## root_mean_squared_error\n",
        "  RMSE_train = np.sqrt(MSE_train)\n",
        "  print(\"RMSE on train is:\" ,RMSE_train)\n",
        "  RMSE_test = np.sqrt(MSE_test)\n",
        "  print(\"RMSE on test is:\" ,RMSE_test)\n",
        "\n",
        "  ## mean_absolute_percentage_error\n",
        "  MAPE_train = mean_absolute_percentage_error(y_train, y_train_pred)*100\n",
        "  print(\"MAPE on train is:\" ,MAPE_train, \" %\")\n",
        "  MAPE_test = mean_absolute_percentage_error(y_test, y_test_pred)*100\n",
        "  print(\"MAPE on test is:\" ,MAPE_test, \" %\")\n",
        "\n",
        "  ## r2_score\n",
        "  R2_train= r2_score(y_train,y_train_pred)\n",
        "  print(\"R2 on train is:\" ,R2_train)  \n",
        "  R2_test= r2_score(y_test,y_test_pred)\n",
        "  print(\"R2 on test is:\" ,R2_test)\n",
        "\n",
        "  Accuracy_train= 100- MAPE_train\n",
        "  print(\"Accuracy of train is:\" ,Accuracy_train, \" %\")\n",
        "  Accuracy_test= 100- MAPE_test\n",
        "  print(\"Accuracy of test is:\" ,Accuracy_test, \" %\")"
      ],
      "metadata": {
        "id": "tj76rnNfnanv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZFcjSjCn3w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing LinearRegression from sklearn\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "f1v-KTbWoLiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "linear_regressor= LinearRegression()\n",
        "# Fit the Algorithm\n",
        "linear_regressor.fit(x_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_regression_pred= linear_regressor.predict(x_train)\n",
        "y_test_regression_pred= linear_regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the coefficients\n",
        "linear_regressor.coef_"
      ],
      "metadata": {
        "id": "9uMGLPdwore8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the intercept\n",
        "linear_regressor.intercept_"
      ],
      "metadata": {
        "id": "8TG04WIYorCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculation of evaluation Metric Score\n",
        "regression_metrics(y_train,y_train_regression_pred,y_test,y_test_regression_pred)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.scatter(y_test,y_test_regression_pred, c=\"blue\")"
      ],
      "metadata": {
        "id": "57yhpDUWHSMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(y_test_regression_pred)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QNIfBbN7H_fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculating residuals\n",
        "residuals = y_test - y_test_regression_pred\n",
        "Mean= round(np.mean(residuals),2)\n",
        "Median= round(np.median(residuals),2)\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.scatter(y_test, residuals, c=\"green\")\n",
        "plt.title(\"Residual Plot for Metric Evaluation\")\n",
        "plt.xlabel('Predicted Sales')\n",
        "plt.ylabel('Residual Error')\n",
        "\n",
        "# Add horizontal line at mean value of y\n",
        "plt.axhline(y=np.nanmean(residuals), color='red', linestyle='--', label=Mean[0])\n",
        "plt.axhline(y=np.nanmedian(residuals), color='blue', linestyle='--', label=Median)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xOLQ5h3gpXLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(8,8))\n",
        "  \n",
        "sns.distplot(y_test- y_test_regression_pred,bins=20)\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20) "
      ],
      "metadata": {
        "id": "v2MGvIa_JUSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter(y_test_regression_pred, y_test-y_test_regression_pred)\n",
        "plt.xlabel('Predicted sales')\n",
        "plt.ylabel('residuals')"
      ],
      "metadata": {
        "id": "p9wFmixKJsGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have applied most basic and simple ML model i.e Linear Regression. We have tried to evaluate the most important regression metrics on both the train and test datesets so that we can conclude our ML model. Here form this plot, we can observe that both the r2 scores are very close which explains that on test dataset and our model is on the correct way."
      ],
      "metadata": {
        "id": "j_l2OTiXqN2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for Ridge Regression"
      ],
      "metadata": {
        "id": "N01yZF70rqKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing ridge regression from sklearn library\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating Ridge instance\n",
        "ridge= Ridge()\n",
        "\n",
        "# Defining parameters\n",
        "parameters = {\"alpha\": [1e-1,1,5,7,10,11,14,15,16,17], \"max_iter\":[1,2,3]}\n",
        "\n",
        "# Train the model\n",
        "ridgeR = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridgeR.fit(x_train,y_train)\n",
        "\n",
        "# Predict the output\n",
        "y_train_ridge_pred = ridgeR.predict(x_train)\n",
        "y_test_ridge_pred = ridgeR.predict(x_test)\n",
        "\n",
        "# Printing the best parameters obtained by GridSearchCV\n",
        "print(f\"The best alpha value found out to be: {ridgeR.best_params_}\")\n",
        "print(f\"Negative mean square error is: {ridgeR.best_score_}\")"
      ],
      "metadata": {
        "id": "xNR94CEhrniq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating regression metrics for Ridge\n",
        "regression_metrics(y_train,y_train_ridge_pred,y_test,y_test_ridge_pred)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Lasso Regression"
      ],
      "metadata": {
        "id": "B0ERg3OEsjty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import lasso regression from sklearn library\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating Ridge instance\n",
        "lasso= Lasso()\n",
        "\n",
        "# Defining parameters\n",
        "parameters_lasso = {\"alpha\": [1e-5,1e-4,1e-3,1e-2,1e-1,1,5], \"max_iter\":[7,8,9,10]}\n",
        "\n",
        "# Train the model\n",
        "lassoR = GridSearchCV(lasso, parameters_lasso, scoring='neg_mean_squared_error', cv=5)\n",
        "lassoR.fit(x_train,y_train)\n",
        "\n",
        "# Predict the output\n",
        "y_train_lasso_pred = lassoR.predict(x_train)\n",
        "y_test_lasso_pred = lassoR.predict(x_test)\n",
        "\n",
        "# Printing the best parameters obtained by GridSearchCV\n",
        "print(f\"The best alpha value found out to be: {lassoR.best_params_}\")\n",
        "print(f\"Negative mean square error is: {lassoR.best_score_}\")"
      ],
      "metadata": {
        "id": "iI4_Pz8yshlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating regression metrics for Lasso\n",
        "regression_metrics(y_train,y_train_lasso_pred,y_test,y_test_lasso_pred)"
      ],
      "metadata": {
        "id": "GFQavPDhso4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9oAw5JDsogi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used GridSearchCV as the hyperparameter optimization technique as it uses all possible combinations of hyperparameters and their values, also it calculates the performance for each combination and selects the best value for the hyperparameters. This offers the most accurate tuning method."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite using Lasso, Ridge models, we couldn't see any significant improvement in the r2 score, MSE and on MAPE as well"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2: Random Forest Regression"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor "
      ],
      "metadata": {
        "id": "DBOOa5iUZ3YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a regressor object\n",
        "RandomForest_TreeR = RandomForestRegressor(n_estimators=100, max_depth=18)"
      ],
      "metadata": {
        "id": "5QUoJ8mYB78b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the regressor with X and Y data\n",
        "RandomForest_TreeR.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "_60xkFvUB7n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting  the model\n",
        "y_train_RFtree_pred= RandomForest_TreeR.predict(x_train)\n",
        "y_test_RFtree_pred= RandomForest_TreeR.predict(x_test)"
      ],
      "metadata": {
        "id": "7iIrsNT8CMl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Regression Metrics using RandomForestRegressor\n",
        "regression_metrics(y_train,y_train_RFtree_pred,y_test,y_test_RFtree_pred)"
      ],
      "metadata": {
        "id": "qwnZNPBYYhYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.scatter(y_test,y_test_RFtree_pred, c=\"blue\")"
      ],
      "metadata": {
        "id": "lnfDdHdoYhDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculating residuals\n",
        "y_test_RFtree_pred= y_test_RFtree_pred.reshape(-1,1)\n",
        "residuals_RandomForest = y_test - y_test_RFtree_pred\n",
        "Mean= round(np.mean(residuals_RandomForest),2)\n",
        "Median= round(np.median(residuals_RandomForest),2)\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.scatter(y_test, residuals_RandomForest, c=\"green\")\n",
        "plt.title(\"Residual Plot for Metric Evaluation\")\n",
        "plt.xlabel('Predicted Sales')\n",
        "plt.ylabel('Residual Error')\n",
        "\n",
        "# Add horizontal line at mean value of y\n",
        "plt.axhline(y=np.nanmean(residuals_RandomForest), color='red', linestyle='--', label=Mean[0])\n",
        "plt.axhline(y=np.nanmedian(residuals_RandomForest), color='black', linestyle='--', label=Median)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BySecLsuHUEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our secomd model i.e Random Forest we have achieved the r2 score of 0.97 on training and 0.95 on test dataset and and that means our model is moving towards optimal model.\n",
        "\n",
        "We got the Mean=0.49 and Median=0.0 this shows that as our accuracy increases, our mean and median are nearly at 0 that means residual error are less.\n",
        "In order to get the higher accuracy let's perform hyperparameter tuning for the same model and see if we are getting significant results."
      ],
      "metadata": {
        "id": "egCjUyiyJISG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ML Model - 2 Implementing with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)"
      ],
      "metadata": {
        "id": "tFxmFWAiLd9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import ridge regression from sklearn library\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Creating Ridge instance\n",
        "RandomForest_tree= RandomForestRegressor()\n",
        "\n",
        "# Defining parameters\n",
        "parameters= {'n_estimators':[100], 'max_depth': [17,19,20], 'min_samples_leaf': [1, 2]}\n",
        "\n",
        "# Train the model\n",
        "RandomForest_treeR = RandomizedSearchCV(RandomForest_tree, parameters, n_iter=5, n_jobs=-1, scoring='neg_mean_squared_error', cv=3,  verbose=3)\n",
        "RandomForest_treeR.fit(x_train,y_train)\n",
        "\n",
        "# Predict the output\n",
        "y_train_grid_RFtree_pred = RandomForest_treeR.predict(x_train)\n",
        "y_test_grid_RFtree_pred = RandomForest_treeR.predict(x_test)\n",
        "\n",
        "# Printing the best parameters obtained by GridSearchCV\n",
        "print(f\"The best alpha value found out to be: {RandomForest_treeR.best_params_}\")\n",
        "print(f\"Negative mean square error is: {RandomForest_treeR.best_score_}\")"
      ],
      "metadata": {
        "id": "GyVB1r-4CaYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_metrics(y_train,y_train_grid_RFtree_pred,y_test,y_test_grid_RFtree_pred)"
      ],
      "metadata": {
        "id": "86Q3iDLmCZ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used RandomizedSearchCV in Random Forest since we have huge dataset and it is good for huge and complex models where we just want to select random parameters from the bag of parameters. It reduces the processing and training time by taking the random subsets of the provided parameters wihout compromising the accuracy of the model."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since predicting sales over a period of time falls under the category of \"Time series data\" and there are following regression metrics that are required as per our goal of analysis (Predicting future Sales):\n",
        "\n",
        "MAE(Mean Absolute Error): This metric calculates the average magnitude of the errors in the predictions, without considering their direction. It has the inverse relation with the accuracy of the model. In regression analysis our aim is to minimise the MAE and ultimately this will create positive business impact.\n",
        "\n",
        "RMSE(Root Mean Squared Error): It is the square root of MSE and this is the most widely use regression metric since it has the same units as the original data so it is easy to interpret the magnitude of error.\n",
        "\n",
        "R2_Score: R2 score(coefficient of determination) is a metric that is widely used in regression analysis because it measures the proportion of the variance in the dependent variable that is explained by the independent variables. R2 score allows analysts to quickly and easily evaluate the goodness of fit of a model and compare different models. It also provides a clear measure of how well the model is explaining the variance in the dependent variable, which can aid in making decisions about model selection and further analysis.\n",
        "\n",
        "MAPE(Mean Absolute Percentage Error): It is calculated by taking the average of the absolute percentage differences between the predicted values and the actual values. This metric is particularly useful when working with time series data(as in our case), as it allows for easy comparison of forecast accuracy across different scales. With the help of MAPE an analyst can easily explain the percentage error to the stakeholders. This metric is considered as one of the most important regression metric in time series data for a positive business impact.\n",
        "\n",
        "Accuracy: In time series data (Such as predicting Sales, Customers, Stock prices, etc) the best metric to calculate the accuracy is 100-MAPE, which is the average of the absolute percentage differences between the predicted values and the actual values. A lower value for 100-MAPE indicates a more accurate mode"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNGCCYDh4bXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}